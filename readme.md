# SF-HFE: Scarcity Framework - Hybrid Federated Expertise

**Production-Grade Online Continual Learning System**

Train General AI with **ZERO initial data** through federated learning, mixture of experts, and P2P gossip protocols.

---

## ğŸ¯ Core Philosophy

**Developer has ZERO initial training data.**  
**Users have local private data.**  
**System learns from user insights only (no raw data sharing).**

---

## ğŸ“ Clean Project Structure

```
sf_hfe_v2/                          â† PRODUCTION SYSTEM
â”‚
â”œâ”€â”€ ğŸ“„ config.py                     â† Central configuration
â”œâ”€â”€ ğŸš€ main.py                       â† Training orchestrator
â”œâ”€â”€ ğŸ¨ dashboard.py                  â† Web UI (dark theme)
â”‚
â”œâ”€â”€ ğŸŒ federated/                    â† FEDERATED LEARNING (Server-side)
â”‚   â”œâ”€â”€ server.py                    â† Central coordinator
â”‚   â”œâ”€â”€ global_memory.py             â† Insight storage
â”‚   â””â”€â”€ meta_learning.py             â† Online MAML engine
â”‚
â”œâ”€â”€ ğŸ§  moe/                          â† MIXTURE OF EXPERTS (Client-side)
â”‚   â”œâ”€â”€ client.py                    â† User device
â”‚   â”œâ”€â”€ router.py                    â† Contextual bandit selector
â”‚   â”œâ”€â”€ base_expert.py               â† Expert foundation
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/                      â† 3-Tier memory system
â”‚   â”‚   â””â”€â”€ hierarchical.py
â”‚   â”‚
â”‚   â””â”€â”€ experts/                     â† 10 Specialized experts
â”‚       â”œâ”€â”€ structure/               â† Core Structure (3)
â”‚       â”‚   â”œâ”€â”€ geometry.py          â† PCA manifolds
â”‚       â”‚   â”œâ”€â”€ temporal.py          â† LSTM sequences
â”‚       â”‚   â””â”€â”€ reconstruction.py    â† VAE reconstruction
â”‚       â”‚
â”‚       â”œâ”€â”€ intelligence/            â† Intelligence (2)
â”‚       â”‚   â”œâ”€â”€ causal.py            â† DAG discovery
â”‚       â”‚   â””â”€â”€ drift.py             â† KL divergence monitoring
â”‚       â”‚
â”‚       â”œâ”€â”€ guardrail/               â† Guardrails (2)
â”‚       â”‚   â”œâ”€â”€ governance.py        â† Constraint validation
â”‚       â”‚   â””â”€â”€ consistency.py       â† Outlier detection
â”‚       â”‚
â”‚       â””â”€â”€ specialized/             â† Specialized (3)
â”‚           â”œâ”€â”€ peer_selection.py    â† P2P topology
â”‚           â”œâ”€â”€ meta_adaptation.py   â† LR scheduling
â”‚           â””â”€â”€ memory_consolidation.py â† Replay orchestration
â”‚
â”œâ”€â”€ ğŸ”— p2p/                          â† P2P GOSSIP (Decentralized)
â”‚   â””â”€â”€ gossip.py                    â† Gossip protocol
â”‚
â””â”€â”€ ğŸ“Š data/                         â† DATA STREAMING
    â””â”€â”€ stream.py                    â† Concept drift generator
```

---

## ğŸš€ Quick Start

### Run Training
```bash
cd sf_hfe_v2
python main.py
```

### Launch Dashboard
```bash
cd sf_hfe_v2
python dashboard.py
# Dashboard opens at http://localhost:8501
```

Or use the launcher:
```bash
cd sf_hfe_v2
RUN_DASHBOARD.bat  # Windows
```

---

## ğŸ’¡ Key Features

### âœ… **Online Continual Learning**
- No pre-training phase
- Learns from scratch on streaming data
- Single-pass through data

### âœ… **10 Specialized Experts** (Organized by Category)
- **Structure (3)**: Geometry, Temporal, Reconstruction
- **Intelligence (2)**: Causal Inference, Drift Detection
- **Guardrail (2)**: Governance, Statistical Consistency
- **Specialized (3)**: Peer Selection, Meta-Adaptation, Memory

### âœ… **Anti-Forgetting Mechanisms**
- 3-tier hierarchical memory (Recent + Compressed + Critical)
- Experience replay with intelligent sampling
- EWC (Elastic Weight Consolidation)
- VAE compression for long-term storage

### âœ… **Adaptive Meta-Learning**
- Online MAML (no pre-training needed)
- Expert-specific learning rates (Î±_i)
- Trigger-based updates (drift, performance, time)

### âœ… **P2P Gossip Protocol**
- Decentralized weight exchange
- Adaptive topology (similarity-based)
- Hysteresis for stability

### âœ… **Privacy-Preserving**
- Insight-based FL (metadata only)
- No raw data/weight sharing with server
- Developer learns from insights, not data

---

## ğŸ“Š Statistics

| Metric | Value |
|--------|-------|
| **Lines of Code** | ~5,000 |
| **Total Experts** | 10 per client |
| **Memory Tiers** | 3 (Recent/Compressed/Critical) |
| **Learning Mode** | Pure Online (no pre-training) |
| **Modules** | 4 (federated/moe/p2p/data) |
| **Organization** | Production-grade OOP |

---

## ğŸ¨ Dashboard (Dark Theme)

Beautiful dark-themed web interface:
- **Background**: Charcoal (#121212)
- **Accents**: Navy Blue (#1F3A93)
- **Text**: Off-white (#EAEAEA)
- **Cards**: Graphite (#1E293B)

---

## ğŸ“– Documentation

- `sf_hfe_v2/README.md` - Detailed module docs
- `sf_hfe_v2/STRUCTURE.md` - Organization guide
- `config.py` - All configuration options
- Each module has comprehensive docstrings

---

## ğŸ”§ Usage Examples

### Import Components

```python
# Federated Learning (Server-side)
from sf_hfe_v2.federated import SFHFEServer, GlobalMemory, OnlineMAMLEngine

# MoE (Client-side)
from sf_hfe_v2.moe import SFHFEClient, ContextualBanditRouter

# Specific expert categories
from sf_hfe_v2.moe.experts.structure import GeometryExpert, TemporalExpert
from sf_hfe_v2.moe.experts.intelligence import CausalInferenceExpert
from sf_hfe_v2.moe.experts.guardrail import GovernanceExpert
from sf_hfe_v2.moe.experts.specialized import MetaAdaptationExpert

# P2P & Data
from sf_hfe_v2.p2p import P2PGossipManager
from sf_hfe_v2.data import ConceptDriftStream
```

### Run Simulation

```python
from sf_hfe_v2.main import OnlineTrainingOrchestrator

# Create system
orchestrator = OnlineTrainingOrchestrator(
    num_clients=5,
    input_dim=20,
    stream_length=10000
)

# Run online training
orchestrator.run_online_training(num_batches=300)
```

---

## ğŸ¯ What Makes This REAL (Not Toy Code)

âœ… **Production architecture** - Clean modules, proper OOP  
âœ… **True online learning** - No batch training or pre-training  
âœ… **Sophisticated experts** - LSTM, VAE, PCA, DAG discovery  
âœ… **Anti-forgetting** - Multi-tier memory + EWC  
âœ… **Adaptive system** - Dynamic LR, freeze/unfreeze  
âœ… **Privacy-first** - Insight-based FL (no raw data)  
âœ… **Scalable design** - Easy to extend and modify  

---

## ğŸš€ Next Steps

1. **Run the system**: `cd sf_hfe_v2 && python main.py`
2. **Explore modules**: Check `federated/`, `moe/`, `p2p/`, `data/`
3. **Customize**: Edit `config.py` for your use case
4. **Add experts**: Drop new experts in appropriate category folder
5. **Version 2.0**: Computer Vision integration coming soon!

---

## ğŸ“ Requirements

```bash
pip install torch numpy matplotlib streamlit pandas
```

See `requirements.txt` for complete list.

---

## ğŸ¤ Developer-User Relationship

1. **Developer** operates server with **ZERO data**
2. **Users** join with their local data streams
3. Users train **10 experts** locally (online learning)
4. Users send **insights** (metadata) to server
5. Server performs **meta-learning** from insights
6. Server broadcasts **meta-parameters** (Î±_i, w_init)
7. Users benefit from **global knowledge** without sharing data
8. **P2P gossip** enables fast local adaptation between similar users

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

**Built for serious AI research and production deployment** ğŸš€

**GitHub**: https://github.com/Omega-Makena/SC-HFI
